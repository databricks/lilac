# Accelerate signals, embeddings, and clustering on Lilac Garden.
use_garden: true

datasets:
  - name: Capybara
    namespace: lilac
    source:
      dataset_name: LDJnr/Capybara
      source_name: huggingface
    settings:
      tags: [datasets]
      ui:
        media_paths:
          - - conversation
            - '*'
            - input
          - - conversation
            - '*'
            - output
    embeddings:
      - embedding: gte-small
        path:
          - conversation
          - '*'
          - input
      - embedding: gte-small
        path:
          - conversation
          - '*'
          - output

  - name: glaive-code-assistant
    namespace: lilac
    source:
      dataset_name: glaiveai/glaive-code-assistant
      source_name: huggingface
    settings:
      tags: [datasets]
      ui:
        media_paths:
          - question
          - answer
          # TODO(nsthorat): Run the map for answer_formatted here and reupload. This is from the
          # blog post about curating a coding dataset.
          # - - answer_formatted
          #   - answer
    embeddings:
      - embedding: gte-small
        path:
          - question
      - embedding: gte-small
        path:
          - answer

  - name: glaive-function-calling-v2
    namespace: lilac
    source:
      dataset_name: lilacai/glaive-function-calling-v2-sharegpt
      source_name: huggingface
    settings:
      tags: [datasets]
      ui:
        media_paths:
          - - conversations
            - '*'
            - value
    embeddings:
      - embedding: gte-small
        path:
          - conversations
          - '*'
          - value

  - name: open-assistant-conversations-2
    namespace: lilac
    settings:
      tags: [datasets]
      ui:
        media_paths:
          - text
    source:
      source_name: huggingface
      dataset_name: OpenAssistant/oasst2
    embeddings:
      - embedding: gte-small
        path:
          - text

  - name: lmsys-chat-1m
    namespace: lilac
    settings:
      tags: [logs]
      ui:
        media_paths:
          - - conversation
            - '*'
            - content
    source:
      source_name: huggingface
      dataset_name: lmsys/lmsys-chat-1m
    embeddings:
      - embedding: gte-small
        path:
          - conversation
          - '*'
          - content

  - name: 'OpenOrca'
    namespace: lilac
    settings:
      tags: [datasets]
      ui:
        media_paths:
          - question
          - response
      preferred_embedding: 'gte-small'
    source:
      source_name: huggingface
      dataset_name: Open-Orca/OpenOrca
    embeddings:
      - embedding: gte-small
        path:
          - question

  - namespace: lilac
    name: mosaic-instruct-v3
    source:
      dataset_name: mosaicml/instruct-v3
      source_name: huggingface
    settings:
      tags: [datasets]
      ui:
        media_paths:
          - prompt
          - response
        markdown_paths: []
    embeddings:
      - embedding: gte-small
        path:
          - prompt

  ## Eval datasets
  - namespace: lilac
    name: MMLU
    source:
      dataset_name: cais/mmlu
      config_name: all
      source_name: huggingface
    settings:
      tags: [eval]
      ui:
        media_paths:
          - question
          - - choices
            - '*'
          - answer

  - namespace: lilac
    name: ARC-Easy
    source:
      dataset_name: allenai/ai2_arc
      config_name: ARC-Easy
      source_name: huggingface
    settings:
      tags: [eval]
      ui:
        media_paths:
          - question
          - - choices
            - text
            - '*'
          - answerKey

  - namespace: lilac
    name: ARC-Challenge
    source:
      dataset_name: allenai/ai2_arc
      config_name: ARC-Challenge
      source_name: huggingface
    settings:
      tags: [eval]
      ui:
        media_paths:
          - question
          - - choices
            - text
            - '*'
          - answerKey

  - namespace: lilac
    name: HellaSwag
    source:
      dataset_name: Rowan/hellaswag
      source_name: huggingface
    settings:
      tags: [eval]
      ui:
        media_paths:
          - ctx
          - ctx_a
          - ctx_b
          - - endings
            - '*'

  - namespace: lilac
    name: HumanEval
    source:
      dataset_name: openai_humaneval
      source_name: huggingface
    settings:
      tags: [eval]
      ui:
        media_paths:
          - prompt
          - canonical_solution
          - test

  - namespace: lilac
    name: mbpp
    source:
      dataset_name: mbpp
      source_name: huggingface
    settings:
      tags: [eval]
      ui:
        media_paths:
          - code
          - text

  - namespace: lilac
    name: TruthfulQA-MultipleChoice
    source:
      dataset_name: truthful_qa
      config_name: multiple_choice
      source_name: huggingface
    settings:
      tags: [eval]
      ui:
        media_paths:
          - question
          - - mc1_targets
            - choices
            - '*'
          - - mc2_targets
            - choices
            - '*'

  - namespace: lilac
    name: TruthfulQA-Generation
    source:
      dataset_name: truthful_qa
      config_name: generation
      source_name: huggingface
    settings:
      tags: [eval]
      ui:
        media_paths:
          - question
          - - correct_answers
            - '*'
          - - incorrect_answers
            - '*'
          - source

  - namespace: lilac
    name: GSM8K-main
    source:
      dataset_name: gsm8k
      config_name: main
      source_name: huggingface
    settings:
      tags: [eval]
      ui:
        media_paths:
          - question
          - answer

  - namespace: lilac
    name: GSM8K-socratic
    source:
      dataset_name: gsm8k
      config_name: socratic
      source_name: huggingface
    settings:
      tags: [eval]
      ui:
        media_paths:
          - question
          - answer

  - namespace: lilac
    name: WinoGrande
    source:
      dataset_name: winogrande
      config_name: winogrande_xl
      source_name: huggingface
    settings:
      tags: [eval]
      ui:
        media_paths:
          - sentence
          - option1
          - option2
          - answer

  ## Old datasets to be cleaned up.
  - name: databricks-dolly-15k-curated-en
    namespace: lilac
    settings:
      tags: [machine-learning]
      ui:
        media_paths:
          - original-instruction
          - original-context
          - original-response
          - - new-instruction
            - value
            - '*'
          - - new-context
            - value
            - '*'
          - - new-response
            - value
            - '*'
    source:
      dataset_name: argilla/databricks-dolly-15k-curated-en
      source_name: huggingface
    embeddings:
      - embedding: gte-small
        path:
          - original-instruction
      - embedding: gte-small
        path:
          - original-context
      - embedding: gte-small
        path:
          - original-response

  - namespace: lilac
    name: dolphin
    tags: [datasets]
    source:
      dataset_name: cognitivecomputations/dolphin
      config_name: flan1m-alpaca-uncensored
      source_name: huggingface
    settings:
      ui:
        media_paths:
          - instruction
          - input
          - output
          - - input__cluster
            - text

signals:
  - signal_name: text_statistics
  - signal_name: lang_detection
  # NOTE: This is currently bugging.
  # - signal_name: concept_score
  #   namespace: lilac
  #   concept_name: profanity
  #   embedding: gte-small

clusters:
  - dataset_namespace: lilac
    dataset_name: Capybara
    input_path:
      - conversation
      - '*'
      - input
  - dataset_namespace: lilac
    dataset_name: glaive-code-assistant
    input_path:
      - question

  - dataset_namespace: lilac
    dataset_name: glaive-function-calling-v2
    input_selector:
      format: sharegpt
      selector: human
    output_path:
      - conversation_clusters

  - dataset_namespace: lilac
    dataset_name: open-assistant-conversations-2
    input_path:
      - text

  - dataset_namespace: lilac
    dataset_name: lmsys-chat-1m
    input_selector:
      format: openai_json
      selector: user
    output_path:
      - conversation__clusters

  - dataset_namespace: lilac
    dataset_name: OpenOrca
    input_path:
      - question

  - dataset_namespace: lilac
    dataset_name: databricks-dolly-15k-curated-en
    input_path:
      - original-instruction

  - dataset_namespace: lilac
    dataset_name: mosaic-instruct-v3
    input_path:
      - prompt

  ## Eval datasets
  - dataset_namespace: lilac
    dataset_name: MMLU
    input_path:
      - question

  - dataset_namespace: lilac
    dataset_name: ARC-Easy
    input_path:
      - question

  - dataset_namespace: lilac
    dataset_name: ARC-Challenge
    input_path:
      - question
  - dataset_namespace: lilac
    dataset_name: HellaSwag
    input_path:
      - ctx

  - dataset_namespace: lilac
    dataset_name: HumanEval
    input_path:
      - prompt

  - dataset_namespace: lilac
    dataset_name: mbpp
    input_path:
      - text

  - dataset_namespace: lilac
    dataset_name: TruthfulQA-Generation
    input_path:
      - question

  - dataset_namespace: lilac
    dataset_name: TruthfulQA-MultipleChoice
    input_path:
      - question

  - dataset_namespace: lilac
    dataset_name: GSM8K-main
    input_path:
      - question

  - dataset_namespace: lilac
    dataset_name: GSM8K-socratic
    input_path:
      - question

  - dataset_namespace: lilac
    dataset_name: WinoGrande
    input_path:
      - sentence

  ## Other datasets
  - dataset_namespace: lilac
    dataset_name: dolphin
    input_path:
      - input

concept_model_cache_embeddings:
  - gte-small
  - gte-base
  - sbert
  - openai
  - cohere
