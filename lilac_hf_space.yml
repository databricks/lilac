# Accelerate signals, embeddings, and clustering on Lilac Garden.
use_garden: true

datasets:
  - name: Capybara
    namespace: lilac
    source:
      dataset_name: LDJnr/Capybara
      source_name: huggingface
    settings:
      tags: [datasets]
      ui:
        media_paths:
          - - conversation
            - '*'
            - input
          - - conversation
            - '*'
            - output
        markdown_paths: []
    embeddings:
      - embedding: gte-small
        path:
          - conversation
          - '*'
          - input
      - embedding: gte-small
        path:
          - conversation
          - '*'
          - output

  - name: glaive-code-assistant
    namespace: lilac
    source:
      dataset_name: glaiveai/glaive-code-assistant
      source_name: huggingface
    settings:
      tags: [datasets]
      ui:
        media_paths:
          - question
          - answer
          # TODO(nsthorat): Run the map for answer_formatted here and reupload. This is from the
          # blog post about curating a coding dataset.
          # - - answer_formatted
          #   - answer
        markdown_paths: []
    embeddings:
      - embedding: gte-small
        path:
          - question
      - embedding: gte-small
        path:
          - answer

  - name: glaive-function-calling-v2
    namespace: lilac
    source:
      dataset_name: lilacai/glaive-function-calling-v2-sharegpt
      source_name: huggingface
    settings:
      tags: [datasets]
      ui:
        media_paths:
          - - conversations
            - '*'
            - value
        markdown_paths: []
    embeddings:
      - embedding: gte-small
        path:
          - conversations
          - '*'
          - value

  - name: open-assistant-conversations-2
    namespace: lilac
    settings:
      tags: [datasets]
      ui:
        media_paths:
          - text
    source:
      source_name: huggingface
      dataset_name: OpenAssistant/oasst2
    embeddings:
      - embedding: gte-small
        path:
          - text

  - name: lmsys-chat-1m
    namespace: lilac
    settings:
      tags: [logs]
      ui:
        media_paths:
          - - conversation
            - '*'
            - content
    source:
      source_name: huggingface
      dataset_name: lmsys/lmsys-chat-1m
    embeddings:
      - embedding: gte-small
        path:
          - conversation
          - '*'
          - content

  ## Old datasets to be cleaned up.
  - name: databricks-dolly-15k-curated-en
    namespace: lilac
    settings:
      tags: [machine-learning]
      ui:
        media_paths:
          - original-instruction
          - original-context
          - original-response
          - - new-instruction
            - value
            - '*'
          - - new-context
            - value
            - '*'
          - - new-response
            - value
            - '*'
    source:
      dataset_name: argilla/databricks-dolly-15k-curated-en
      source_name: huggingface
    embeddings:
      - embedding: gte-small
        path:
          - original-instruction
      - embedding: gte-small
        path:
          - original-context
      - embedding: gte-small
        path:
          - original-response

  - name: 'OpenOrca'
    namespace: lilac
    settings:
      tags: [datasets]
      ui:
        media_paths:
          - question
          - response
      preferred_embedding: 'gte-small'
    source:
      source_name: huggingface
      dataset_name: Open-Orca/OpenOrca
    embeddings:
      - embedding: gte-small
        path:
          - question

  - namespace: lilac
    name: dolphin
    tags: [datasets]
    source:
      dataset_name: cognitivecomputations/dolphin
      config_name: flan1m-alpaca-uncensored
      source_name: huggingface
    settings:
      ui:
        media_paths:
          - instruction
          - input
          - output
          - - input__cluster
            - text
        markdown_paths: []

signals:
  - signal_name: text_statistics
  - signal_name: lang_detection
  # NOTE: This is currently bugging.
  # - signal_name: concept_score
  #   namespace: lilac
  #   concept_name: profanity
  #   embedding: gte-small

clusters:
  - dataset_namespace: lilac
    dataset_name: Capybara
    input_path:
      - conversation
      - '*'
      - input
  - dataset_namespace: lilac
    dataset_name: glaive-code-assistant
    input_path:
      - question
  - dataset_namespace: lilac
    dataset_name: glaive-function-calling-v2
    input_selector:
      format: sharegpt
      selector: human
    output_path:
      - conversation_clusters
  - dataset_namespace: lilac
    dataset_name: open-assistant-conversations-2
    input_path:
      - text
  - dataset_namespace: lilac
    dataset_name: lmsys-chat-1m
    input_selector:
      format: openai_json
      selector: user
    output_path:
      - conversation__clusters
  - dataset_namespace: lilac
    dataset_name: OpenOrca
    input_path:
      - question
  - dataset_namespace: lilac
    dataset_name: databricks-dolly-15k-curated-en
    input_path:
      - original-instruction
  - dataset_namespace: lilac
    dataset_name: dolphin
    input_path:
      - input

concept_model_cache_embeddings:
  - gte-small
  - gte-base
  - sbert
  - openai
  - cohere
  # PALM is currently timing-out.
  # - palm
