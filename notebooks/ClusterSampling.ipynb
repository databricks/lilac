{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using clusters to sample a dataset\n",
    "\n",
    "This notebook will show you how to use computed clusters to sub-sample a dataset. We're going to create a distilled version of SlimOrca that only has translation-related conversations, and publish it to HuggingFace.\n",
    "\n",
    "For more details on clustering, see our [Clustering](https://docs.lilacml.com/datasets/dataset_cluster.html) guide.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhil/Code/lilac/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lilac as ll\n",
    "\n",
    "ll.set_project_dir('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the lilac-processed OpenOrca dataset.\n",
    "if not ll.has_dataset('lilac', 'SlimOrca'):\n",
    "  ll.download('lilacai/lilac-SlimOrca', dataset_namespace='lilac', dataset_name='SlimOrca')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the first row\n",
    "\n",
    "Let's print the first row to see how the data is shaped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__hfsplit__': 'train',\n",
      " 'conversation__clusters': {'category_id': 135,\n",
      "                            'category_membership_prob': 0.8721028566360474,\n",
      "                            'category_title': 'Data Extraction',\n",
      "                            'cluster_id': 6345,\n",
      "                            'cluster_membership_prob': 1.0,\n",
      "                            'cluster_title': 'Structured Data Extraction and '\n",
      "                                             'Description'},\n",
      " 'conversations': [{'from': 'system',\n",
      "                    'value': 'You are an AI assistant. User will you give you '\n",
      "                             'a task. Your goal is to complete the task as '\n",
      "                             'faithfully as you can. While performing the task '\n",
      "                             'think step-by-step and justify your steps.',\n",
      "                    'weight': None},\n",
      "                   {'from': 'human',\n",
      "                    'value': 'Data: Maryland (3) SUCCESSOR John Creswell (UU); '\n",
      "                             'John Creswell (UU) '\n",
      "                             'DATE_OF_SUCCESSORS_FORMAL_INSTALLATION March 9, '\n",
      "                             '1865; Vacant REASON_FOR_CHANGE Sen. Thomas H. '\n",
      "                             'Hicks died during previous congress; Maryland '\n",
      "                             '(3) VACATOR Vacant\\n'\n",
      "                             '\\n'\n",
      "                             'What would a sentence about this data be like?',\n",
      "                    'weight': 0.0},\n",
      "                   {'from': 'gpt',\n",
      "                    'value': 'On March 9, 1865, John Creswell (UU) was '\n",
      "                             'formally installed as the successor for the '\n",
      "                             'Maryland (3) congressional seat, following the '\n",
      "                             'death of Sen. Thomas H. Hicks during the '\n",
      "                             'previous congress, which had left the seat '\n",
      "                             'vacant.',\n",
      "                    'weight': 1.0}]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "ds = ll.get_dataset('lilac', 'SlimOrca')\n",
    "\n",
    "# Print the first row.\n",
    "pprint(next(ds.select_rows(limit=1, combine_columns=True, exclude_signals=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the top cluster categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Translation', 42628),\n",
      " ('Entailment and Hypothesis', 36039),\n",
      " ('Mathematics', 22703),\n",
      " ('Sentiment Analysis', 20037),\n",
      " ('Fact-Checking', 12285),\n",
      " ('Text Classification', 11307),\n",
      " ('Sentence Analysis', 11100),\n",
      " ('Inference Questions', 10345),\n",
      " ('News Summarization', 9998),\n",
      " ('Reading Comprehension', 9896)]\n"
     ]
    }
   ],
   "source": [
    "groups = ds.select_groups('conversation__clusters.category_title')\n",
    "\n",
    "# Print the top-10 cluster categories.\n",
    "pprint(groups.counts[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a HuggingFace dataset with just the translation cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['conversations', '__hfsplit__', 'conversation__clusters'],\n",
      "    num_rows: 42628\n",
      "})\n",
      "{'__hfsplit__': 'train',\n",
      " 'conversation__clusters': {'category_id': 163,\n",
      "                            'category_membership_prob': 0.5394969582557678,\n",
      "                            'category_title': 'Translation',\n",
      "                            'cluster_id': 1848,\n",
      "                            'cluster_membership_prob': 0.6829708218574524,\n",
      "                            'cluster_title': 'Translation Verification in '\n",
      "                                             'Japanese and Filipino'},\n",
      " 'conversations': [{'from': 'human',\n",
      "                    'value': 'Q: Given a sentence in the Japanese and Filipino '\n",
      "                             'language. Your task is check if the Filipino '\n",
      "                             'sentence is translation of Japanese. if the '\n",
      "                             'translation is correct than generate label '\n",
      "                             '\"Yes\", otherwise generate label \"No\".\\n'\n",
      "                             'Japanese: '\n",
      "                             'ベルへはBBCに、グループがお金を得るためには「芝居」を打つことだってすると言った。 \\n'\n",
      "                             ' Filipino: \"Ang praktikal na katotohanan ay ang '\n",
      "                             'dalawang pinakamalaking partido ay hindi '\n",
      "                             'ipinapakita na handa silang magpatuloy.\"\\n'\n",
      "                             'A:',\n",
      "                    'weight': 0.0},\n",
      "                   {'from': 'gpt', 'value': 'No', 'weight': 1.0}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 43/43 [00:00<00:00, 302.64ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:47<00:00, 47.07s/it]\n"
     ]
    }
   ],
   "source": [
    "hf_ds = ds.to_huggingface(\n",
    "  filters=[('conversation__clusters.category_title', 'equals', 'Translation')],\n",
    ")\n",
    "\n",
    "print(hf_ds)\n",
    "pprint(hf_ds[0])\n",
    "\n",
    "# Publish to the HuggingFace hub.\n",
    "hf_ds.push_to_hub('lilacai/SlimOrca-Translation')\n",
    "\n",
    "# This creates https://huggingface.co/datasets/lilacai/SlimOrca-Translation\n",
    "# Success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
