{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/dev/lilac/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lilac as ll\n",
    "\n",
    "ll.set_project_dir('data')\n",
    "\n",
    "# slimorca = ll.get_dataset('local', 'slimorca')\n",
    "# slimorca.compute_embedding('gte-small')\n",
    "# slimorca.select_rows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ll.get_dataset('local', 'openorca-10k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = list(ds.select_rows(columns=['question']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [row['question'] for row in rows[:1000]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import functools\n",
    "from lilac.splitters.spacy_splitter import clustering_spacy_chunker\n",
    "from lilac.embeddings.embedding import compute_split_embeddings\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def time_it(model, texts, batch_size, megabatch_size):\n",
    "  start = time.time()\n",
    "  embed_fn = functools.partial(model.encode, batch_size=batch_size)\n",
    "  split_fn = clustering_spacy_chunker\n",
    "  list(\n",
    "    tqdm.tqdm(\n",
    "      compute_split_embeddings(texts, megabatch_size, embed_fn=embed_fn, split_fn=split_fn)))\n",
    "  end = time.time()\n",
    "  return end - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:09, 101.07it/s]\n",
      "1000it [00:10, 98.47it/s]\n",
      "1000it [00:09, 104.17it/s]\n",
      "1000it [00:09, 104.78it/s]\n",
      "1000it [00:14, 68.16it/s]\n",
      "1000it [00:11, 84.71it/s]\n",
      "1000it [00:11, 89.57it/s]\n",
      "1000it [00:10, 94.28it/s]\n",
      "1000it [00:16, 59.55it/s]\n",
      "1000it [00:14, 71.09it/s]\n",
      "1000it [00:14, 67.77it/s]\n",
      "1000it [00:13, 74.63it/s]\n",
      "Downloading (…)a8668/.gitattributes: 100%|██████████| 1.52k/1.52k [00:00<00:00, 5.95MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 1.25MB/s]\n",
      "Downloading (…)10cbba8668/README.md: 100%|██████████| 68.1k/68.1k [00:00<00:00, 78.9MB/s]\n",
      "Downloading (…)cbba8668/config.json: 100%|██████████| 618/618 [00:00<00:00, 4.69MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 219M/219M [00:22<00:00, 9.90MB/s] \n",
      "Downloading (…)668/onnx/config.json: 100%|██████████| 630/630 [00:00<00:00, 3.71MB/s]\n",
      "Downloading model.onnx: 100%|██████████| 436M/436M [00:42<00:00, 10.3MB/s] \n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 438kB/s]\n",
      "Downloading (…)/onnx/tokenizer.json: 100%|██████████| 712k/712k [00:00<00:00, 9.31MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 314/314 [00:00<00:00, 2.16MB/s]\n",
      "Downloading (…)a8668/onnx/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 903kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 219M/219M [00:22<00:00, 9.91MB/s] \n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 57.0/57.0 [00:00<00:00, 236kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 771kB/s]\n",
      "Downloading (…)a8668/tokenizer.json: 100%|██████████| 712k/712k [00:00<00:00, 14.6MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 314/314 [00:00<00:00, 1.75MB/s]\n",
      "Downloading (…)10cbba8668/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 17.5MB/s]\n",
      "Downloading (…)bba8668/modules.json: 100%|██████████| 385/385 [00:00<00:00, 1.79MB/s]\n",
      "1000it [00:28, 35.57it/s]\n",
      "1000it [00:22, 45.15it/s]\n",
      "1000it [00:21, 46.38it/s]\n",
      "1000it [00:21, 46.97it/s]\n",
      "1000it [00:27, 36.48it/s]\n",
      "1000it [00:24, 40.10it/s]\n",
      "1000it [00:24, 40.49it/s]\n",
      "1000it [00:23, 41.75it/s]\n",
      "1000it [00:36, 27.54it/s]\n",
      "1000it [00:31, 31.37it/s]\n",
      "1000it [00:32, 30.31it/s]\n",
      "1000it [00:31, 32.17it/s]\n",
      "Downloading (…)e9125/.gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 3.61MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 1.53MB/s]\n",
      "Downloading (…)7e55de9125/README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 21.1MB/s]\n",
      "Downloading (…)55de9125/config.json: 100%|██████████| 612/612 [00:00<00:00, 5.14MB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 975kB/s]\n",
      "Downloading (…)125/data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 46.7MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:08<00:00, 11.2MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 262kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 444kB/s]\n",
      "Downloading (…)e9125/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 6.06MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 1.02MB/s]\n",
      "Downloading (…)9125/train_script.py: 100%|██████████| 13.2k/13.2k [00:00<00:00, 21.2MB/s]\n",
      "Downloading (…)7e55de9125/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 942kB/s]\n",
      "Downloading (…)5de9125/modules.json: 100%|██████████| 349/349 [00:00<00:00, 992kB/s]\n",
      "1000it [00:06, 163.04it/s]\n",
      "1000it [00:05, 181.90it/s]\n",
      "1000it [00:05, 184.14it/s]\n",
      "1000it [00:05, 185.99it/s]\n",
      "1000it [00:06, 162.02it/s]\n",
      "1000it [00:05, 170.55it/s]\n",
      "1000it [00:05, 172.36it/s]\n",
      "1000it [00:05, 180.34it/s]\n",
      "1000it [00:07, 137.87it/s]\n",
      "1000it [00:06, 151.03it/s]\n",
      "1000it [00:06, 142.93it/s]\n",
      "1000it [00:06, 155.97it/s]\n"
     ]
    }
   ],
   "source": [
    "data_rows = []\n",
    "for model_name in ('thenlper/gte-small', 'thenlper/gte-base', 'all-MiniLM-L6-v2'):\n",
    "  model = SentenceTransformer(model_name, device='mps')\n",
    "  for batch_size in (32, 64, 128):\n",
    "    for megabatch_size in (256, 512, 1024, 2048):\n",
    "      data_rows.append({\n",
    "        'model': model_name,\n",
    "        'batch_size': batch_size,\n",
    "        'megabatch_size': megabatch_size,\n",
    "        'time': time_it(model, texts, batch_size, megabatch_size)\n",
    "      })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "      <th>128</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>megabatch_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">all-MiniLM-L6-v2</th>\n",
       "      <th>256</th>\n",
       "      <td>6.14</td>\n",
       "      <td>6.17</td>\n",
       "      <td>7.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>5.50</td>\n",
       "      <td>5.87</td>\n",
       "      <td>6.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>5.43</td>\n",
       "      <td>5.80</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>5.38</td>\n",
       "      <td>5.55</td>\n",
       "      <td>6.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">thenlper/gte-base</th>\n",
       "      <th>256</th>\n",
       "      <td>28.12</td>\n",
       "      <td>27.41</td>\n",
       "      <td>36.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>22.15</td>\n",
       "      <td>24.94</td>\n",
       "      <td>31.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>21.56</td>\n",
       "      <td>24.70</td>\n",
       "      <td>33.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>21.29</td>\n",
       "      <td>23.96</td>\n",
       "      <td>31.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">thenlper/gte-small</th>\n",
       "      <th>256</th>\n",
       "      <td>9.90</td>\n",
       "      <td>14.67</td>\n",
       "      <td>16.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>10.16</td>\n",
       "      <td>11.81</td>\n",
       "      <td>14.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>9.60</td>\n",
       "      <td>11.17</td>\n",
       "      <td>14.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>9.55</td>\n",
       "      <td>10.61</td>\n",
       "      <td>13.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "batch_size                           32     64     128\n",
       "model              megabatch_size                     \n",
       "all-MiniLM-L6-v2   256              6.14   6.17   7.26\n",
       "                   512              5.50   5.87   6.62\n",
       "                   1024             5.43   5.80   7.00\n",
       "                   2048             5.38   5.55   6.41\n",
       "thenlper/gte-base  256             28.12  27.41  36.32\n",
       "                   512             22.15  24.94  31.88\n",
       "                   1024            21.56  24.70  33.00\n",
       "                   2048            21.29  23.96  31.09\n",
       "thenlper/gte-small 256              9.90  14.67  16.79\n",
       "                   512             10.16  11.81  14.07\n",
       "                   1024             9.60  11.17  14.76\n",
       "                   2048             9.55  10.61  13.40"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(data_rows).pivot(\n",
    "  columns='batch_size', index=['model', 'megabatch_size'], values='time').round(2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
