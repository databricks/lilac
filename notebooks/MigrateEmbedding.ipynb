{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Migrates the embedding from the old format to the new format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lilac as ll\n",
    "\n",
    "namespace = 'local'\n",
    "dataset_name = 'twitter-support'\n",
    "path = 'text'\n",
    "embedding = 'cohere'\n",
    "signal_dir = os.path.join('data', 'datasets', namespace, dataset_name, path, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lilac.data.dataset_duckdb import SignalManifest\n",
    "\n",
    "signal_manifest_path = os.path.join(signal_dir, 'signal_manifest.json')\n",
    "with open(signal_manifest_path) as f:\n",
    "  signal_manifest = SignalManifest.parse_raw(f.read())\n",
    "  embedding_filename_prefix = signal_manifest.embedding_filename_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote data/datasets/local/twitter-support/text/cohere/embeddings-00000-of-00001.spans.pkl\n",
      "Edited data/datasets/local/twitter-support/text/cohere/signal_manifest.json\n"
     ]
    }
   ],
   "source": [
    "from lilac.schema import PathKey\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ds = ll.get_dataset(namespace, dataset_name)\n",
    "emd_path = (path, embedding)\n",
    "df = ds.select_rows([ll.Column(emd_path, alias='val')]).df()\n",
    "\n",
    "all_spans: list[tuple[PathKey, list[tuple[int, int]]]] = []\n",
    "num_spans = 0\n",
    "for _, row in df.iterrows():\n",
    "  id = (row['__rowid__'],)\n",
    "  spans: list[tuple[int, int]] = [\n",
    "    (int(x['__value__']['start']), int(x['__value__']['end'])) for x in row['val']\n",
    "  ]\n",
    "  num_spans += len(spans)\n",
    "  all_spans.append((id, spans))\n",
    "\n",
    "# Make sure the embeddings length matches the number of spans.\n",
    "embeddings = np.load(\n",
    "  os.path.join(signal_dir, f'{embedding_filename_prefix}.npy'), allow_pickle=False)\n",
    "assert len(embeddings) == num_spans\n",
    "\n",
    "spans_fname = os.path.join(signal_dir, f'{embedding_filename_prefix}.spans.pkl')\n",
    "with open(spans_fname, 'wb') as f:\n",
    "  pickle.dump(all_spans, f)\n",
    "print('Wrote', spans_fname)\n",
    "\n",
    "signal_manifest.files = []\n",
    "with open(signal_manifest_path, 'w') as f:\n",
    "  f.write(signal_manifest.json(exclude_none=True, indent=2))\n",
    "\n",
    "print('Edited', signal_manifest_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
