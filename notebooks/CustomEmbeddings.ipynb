{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom embeddings\n",
    "\n",
    "This notebook will show to use custom embeddings in Lilac.\n",
    "\n",
    "When making a custom embedding, you have to register an embedding function with Lilac, but you do not have to compute embeddings for the entire dataset in Lilac. Embeddings from an existing vector store can be loaded with [`Dataset.load_embeddings`](https://docs.lilacml.com/api_reference/data.html#lilac.data.Dataset.load_embeddings)\n",
    "\n",
    "For more information on embeddings, see our [Embeddings](https://docs.lilacml.com/datasets/dataset_embeddings.html) guide.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhil/Code/lilac/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import lilac as ll\n",
    "\n",
    "ll.set_project_dir('./data')\n",
    "\n",
    "items = [\n",
    "  {'id': '0_', 'text': 'This is some fake data'},\n",
    "  {'id': '1_', 'text': 'This is some more fake data'},\n",
    "  {'id': '2_', 'text': 'This is even more fake data'},\n",
    "  {'id': '3_', 'text': 'I love plants'},\n",
    "]\n",
    "# Load a fake dataset from dictionaries.\n",
    "try:\n",
    "  ds = ll.get_dataset('local', 'load_embedding')\n",
    "except Exception as e:\n",
    "  ds = ll.from_dicts('local', 'load_embedding', items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register an embedding function\n",
    "\n",
    "For embeddings to be useful in Lilac, we must be able to compute new embeddings\n",
    "\n",
    "This means we have to register an embedding function under a name so that we can call it from semantic searches (embedding the query) or from concept search (embedding concept data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the embedding on a single item...\n",
      "[{'__span__': {'start': 0, 'end': 17}, 'embedding': array([-4.39735241e-02, -9.28446930e-03,  4.57611308e-02, -3.19548771e-02,\n",
      "        8.43660533e-03,  9.48431529e-03,  5.90084903e-02,  5.59187271e-02,\n",
      "       -1.78449824e-02, -5.01370244e-02,  8.36663414e-03, -5.73770069e-02,\n",
      "        9.36811697e-03,  1.31201018e-02, -1.38591407e-02, -2.79680942e-03,\n",
      "        1.27376560e-02, -2.13926788e-02, -5.75558171e-02,  3.24781537e-02,\n",
      "        7.07704574e-02,  2.67298613e-02, -2.15108655e-02, -1.52723445e-02,\n",
      "        5.37770353e-02,  2.32838802e-02, -1.45876221e-02, -3.92815508e-02,\n",
      "       -8.67534149e-03, -1.66421592e-01, -7.23247370e-03,  2.60695047e-03,\n",
      "        4.72562760e-02, -5.58551177e-02, -1.39868818e-03, -8.96183029e-03,\n",
      "       -5.59775271e-02,  6.02203384e-02, -2.89687067e-02,  3.60556208e-02,\n",
      "        3.68024521e-02, -3.64479795e-02, -5.02835214e-03, -4.53025363e-02,\n",
      "       -2.61498820e-02, -7.03798011e-02, -5.70576228e-02, -3.78287770e-02,\n",
      "        1.76253114e-02, -4.91252914e-02,  2.62264106e-02,  9.68559354e-04,\n",
      "       -4.24263300e-03, -7.24040298e-03,  1.87096968e-02,  4.51337509e-02,\n",
      "        5.70538789e-02,  4.94649746e-02,  3.54286842e-02,  1.33729139e-02,\n",
      "        3.20986249e-02,  3.85782048e-02, -2.25227967e-01,  1.25819832e-01,\n",
      "        2.57874522e-02,  3.28232744e-03, -3.83680612e-02, -2.30490186e-04,\n",
      "        5.14140092e-02,  3.93648520e-02, -3.75990160e-02,  2.29944550e-02,\n",
      "        1.89062431e-02,  6.84182495e-02, -7.92450085e-03, -2.69938596e-02,\n",
      "       -3.01054977e-02, -4.91223559e-02,  8.13283399e-03,  2.19072197e-02,\n",
      "        3.33208754e-03, -2.19486319e-02,  1.44597339e-02, -3.38134170e-03,\n",
      "       -5.36277071e-02, -5.32854572e-02, -9.22775827e-03, -2.93167438e-02,\n",
      "        4.00652848e-02, -1.89703761e-03, -2.98962276e-02, -7.73666147e-03,\n",
      "        2.39082146e-02,  8.84186197e-03, -4.58775237e-02, -1.93526261e-02,\n",
      "        3.40101533e-02, -6.99519133e-03,  1.11258728e-02,  2.32716054e-01,\n",
      "       -6.28979802e-02,  2.47108098e-02,  4.64564413e-02, -9.61099006e-03,\n",
      "        1.02606900e-02, -2.15526689e-02,  1.26665747e-02, -4.23083417e-02,\n",
      "       -3.75740528e-02,  1.82393268e-02, -3.29855038e-03, -1.52005898e-02,\n",
      "        9.17492993e-03, -2.25046780e-02,  4.73027304e-02, -1.30696893e-02,\n",
      "        6.55562282e-02,  3.80051993e-02, -9.58174816e-04,  1.14183538e-02,\n",
      "       -1.91028118e-02,  1.60282142e-02,  1.43870199e-02, -1.42485043e-02,\n",
      "        6.50884211e-02, -7.10930154e-02,  6.00317754e-02,  1.02917612e-01,\n",
      "        5.39738908e-02,  1.84119977e-02,  4.23884019e-02,  9.11878515e-03,\n",
      "       -3.11106928e-02, -3.48473899e-02, -3.50664258e-02,  1.51163395e-02,\n",
      "       -1.38842324e-02,  2.60395231e-03,  2.15508882e-02, -6.76768646e-02,\n",
      "       -2.39691865e-02, -1.36866286e-01, -2.43556332e-02, -1.19492628e-01,\n",
      "       -6.14276789e-02,  6.34225756e-02,  3.73305473e-03,  5.43350615e-02,\n",
      "       -5.55165932e-02, -1.34935156e-02, -1.31179951e-02,  5.41530959e-02,\n",
      "       -2.14719921e-02, -1.21977832e-02,  2.52397116e-02, -2.74596009e-02,\n",
      "        3.97148393e-02,  3.62676233e-02, -6.06627017e-02,  3.13008167e-02,\n",
      "        2.00557169e-02, -3.79323550e-02, -3.25453877e-02,  1.27246231e-01,\n",
      "        3.04672904e-02, -1.11378610e-01, -4.22729589e-02, -1.62340216e-02,\n",
      "        8.47518910e-03, -2.65603680e-02,  2.88859941e-02,  2.67571006e-02,\n",
      "       -4.13879007e-02,  6.14852756e-02,  6.53700083e-02,  1.51177403e-02,\n",
      "       -2.98494697e-02,  4.26297355e-03, -5.43835294e-03,  3.34546305e-02,\n",
      "        4.01177481e-02, -4.11894284e-02, -3.45960706e-02,  5.58982305e-02,\n",
      "        2.79217456e-02, -3.21064591e-02, -1.62213482e-02, -6.21478632e-02,\n",
      "        2.12123916e-02,  2.06543114e-02, -2.30661631e-02,  7.18063042e-02,\n",
      "       -2.45512538e-02, -3.26925442e-02, -6.34562224e-02, -2.92757712e-03,\n",
      "       -2.57320851e-02, -3.79187465e-02, -2.07359642e-02, -3.02065611e-02,\n",
      "        4.48752083e-02,  2.00069454e-02, -4.80789989e-02,  2.60105990e-02,\n",
      "        7.46281678e-03,  1.74651816e-02,  1.13370372e-02,  5.61753463e-04,\n",
      "        1.12274289e-02, -3.03209145e-02, -3.99290211e-02,  5.21994308e-02,\n",
      "        1.87836625e-02, -1.57606194e-03, -1.87910497e-02, -1.62748285e-02,\n",
      "        1.14851594e-02,  4.17079479e-02, -1.86803006e-02,  1.55243818e-02,\n",
      "       -1.01187732e-02, -8.63769054e-02, -4.49596941e-02, -2.31446773e-01,\n",
      "        1.43295275e-02,  1.12035060e-02, -4.86242212e-02,  3.97708677e-02,\n",
      "       -1.69103984e-02,  3.39829512e-02, -2.23324727e-02,  5.07147647e-02,\n",
      "        7.55643025e-02,  7.00387731e-02, -2.80953906e-02, -2.14203279e-02,\n",
      "       -4.23438818e-04,  1.53467804e-02,  5.40248156e-02,  7.39449682e-03,\n",
      "        1.60025600e-02,  2.21551885e-03,  2.02767253e-02, -1.84773915e-02,\n",
      "       -1.01584112e-02, -2.82454230e-02, -4.33561541e-02,  4.88963164e-02,\n",
      "       -1.18346820e-02,  2.21260265e-01,  1.15226172e-01,  2.93488204e-02,\n",
      "       -5.76255023e-02,  5.14890254e-02,  2.13495232e-02,  4.32722270e-03,\n",
      "       -7.80859962e-02,  4.26553674e-02,  3.94582897e-02,  1.01066483e-02,\n",
      "       -1.70017518e-02, -4.47423160e-02, -3.73657886e-03, -9.89677198e-03,\n",
      "        6.46085218e-02,  2.89389980e-03, -5.78800850e-02, -4.39192243e-02,\n",
      "       -5.09524234e-02, -3.47328335e-02, -1.45356432e-02, -6.81961998e-02,\n",
      "        3.99697945e-02,  3.05952039e-02, -4.30575125e-02,  2.90555712e-02,\n",
      "        4.61442769e-02,  2.96799801e-02, -1.31074646e-02, -1.21429950e-01,\n",
      "        9.44986660e-03, -3.08850221e-02,  2.88082231e-02,  2.59405328e-03,\n",
      "       -1.68599263e-02,  1.58408340e-02, -4.99515124e-02,  3.71913016e-02,\n",
      "        3.20708752e-02, -1.60497464e-02, -5.91248572e-02,  2.48909499e-02,\n",
      "       -1.07513927e-02, -5.60467271e-03,  3.16081978e-02, -3.61951180e-02,\n",
      "       -4.27424312e-02,  3.86971235e-02,  5.90188541e-02,  4.91246320e-02,\n",
      "        1.42127704e-02, -4.47982103e-02, -3.10373083e-02,  1.02228113e-02,\n",
      "        8.65050778e-03,  1.59131363e-02,  5.04547879e-02, -9.12769232e-03,\n",
      "        9.22143832e-03,  3.87291238e-02, -5.03061414e-02,  5.30913286e-02,\n",
      "       -3.43675725e-02,  6.50202483e-03,  5.21517619e-02, -2.89056897e-02,\n",
      "       -4.51964997e-02,  7.40819331e-03, -3.08206566e-02, -3.00171822e-01,\n",
      "        3.75145711e-02, -4.50131157e-03, -2.01970781e-03, -4.40680832e-02,\n",
      "        3.91510874e-02,  5.92548065e-02,  5.69307730e-02, -1.05794609e-01,\n",
      "        1.10388212e-02, -9.41633899e-03,  4.97216210e-02,  1.24368528e-02,\n",
      "       -1.68958362e-02, -1.18479291e-02,  4.82368506e-02,  8.50489512e-02,\n",
      "       -8.80272165e-02, -8.02026480e-04, -7.85567537e-02,  8.76908936e-03,\n",
      "        7.00512994e-03,  1.91530406e-01, -2.53157225e-02,  4.18267306e-03,\n",
      "        3.29622924e-02, -9.14285332e-03,  1.53724607e-02,  6.52871057e-02,\n",
      "       -2.34898105e-02,  5.69275431e-02,  1.43813901e-02,  9.45839882e-02,\n",
      "       -2.04234049e-02,  6.41784072e-02,  5.14972780e-04, -2.62881890e-02,\n",
      "        4.79228534e-02,  1.62316358e-03,  2.92370096e-02, -2.18462534e-02,\n",
      "        5.08508906e-02, -1.07988857e-01, -1.55504746e-02,  1.15721837e-01,\n",
      "        1.38980998e-02, -7.17592798e-03, -4.22822312e-02,  8.29605479e-03,\n",
      "        3.38608921e-02, -6.07384667e-02,  4.37516794e-02, -2.34813225e-02,\n",
      "       -1.69972684e-02,  3.54364067e-02,  5.95175140e-02, -4.48691398e-02,\n",
      "       -5.69155253e-02, -3.76485959e-02, -9.80093703e-03,  3.81507422e-03,\n",
      "       -3.69908325e-02, -3.02194487e-02,  7.84944370e-02,  6.18109666e-02],\n",
      "      dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "try:\n",
    "  from sentence_transformers import SentenceTransformer\n",
    "except ImportError:\n",
    "  raise ImportError(\n",
    "    'Could not import the \"sentence_transformers\" python package. '\n",
    "    'Please install it with `pip install \"sentence_transformers\".'\n",
    "  )\n",
    "\n",
    "embedding_model = SentenceTransformer('thenlper/gte-small')\n",
    "\n",
    "\n",
    "def _embed(text):\n",
    "  # Call the gte-small embedding model.\n",
    "  return np.array(embedding_model.encode(text))\n",
    "\n",
    "\n",
    "# Make an embedding class.\n",
    "class MyEmbedding(ll.TextEmbeddingSignal):\n",
    "  name = 'my_embedding'\n",
    "\n",
    "  def compute(self, data):\n",
    "    for text in data:\n",
    "      embedding = _embed(text)\n",
    "      # Yield a full chunk embedding. If you want to chunk your text, yield an array here.\n",
    "      yield [ll.chunk_embedding(0, len(text), embedding)]\n",
    "\n",
    "\n",
    "print('Testing the embedding on a single item...')\n",
    "print(next(MyEmbedding().compute(['This is some text'])))\n",
    "\n",
    "# Register the embedding under 'my_embedding' so it can be used by Lilac.\n",
    "ll.register_embedding(MyEmbedding, exists_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load full-document embeddings from our vector store\n",
    "\n",
    "First, let's compute full-document embeddings manually with gte-small, from the sentence_transformers library.\n",
    "\n",
    "Our vector store is just a dictionary in this example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load embedding my_embedding on load_embedding:('text',): 100%|██████████| 4/4 [00:00<00:00, 2032.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hnswlib index creation took 0.001s.\n",
      "hnswlib add items took 0.000s.\n",
      "Wrote embedding index to ./data/datasets/local/load_embedding/text/my_embedding\n"
     ]
    }
   ],
   "source": [
    "vector_store = {}\n",
    "for item in items:\n",
    "  vector_store[item['id']] = _embed(item['text'])\n",
    "\n",
    "\n",
    "# Load the embeddings into Lilac.\n",
    "def _load_embedding(item):\n",
    "  return vector_store[item['id']]\n",
    "\n",
    "\n",
    "# Load the embeddings into Lilac.\n",
    "ds.load_embedding(\n",
    "  load_fn=_load_embedding, index_path='text', embedding='my_embedding', overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic search with our custom embedding\n",
    "\n",
    "Now we can rank documents with our custom embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing signal \"semantic_similarity\" on local/load_embedding:('text',) took 0.016s.\n",
      "This is some fake data 0.9254916310310364\n",
      "This is some more fake data 0.9084776043891907\n",
      "This is even more fake data 0.8841889500617981\n",
      "I love plants 0.7808101177215576\n"
     ]
    }
   ],
   "source": [
    "# Select rows using a semantic search.\n",
    "rows = ds.select_rows(\n",
    "  ['text'],\n",
    "  searches=[\n",
    "    ll.SemanticSearch(path='text', query='This is some data', embedding='my_embedding'),\n",
    "  ],\n",
    ")\n",
    "\n",
    "for row in rows:\n",
    "  print(\n",
    "    row['text'],\n",
    "    row['text.semantic_similarity(embedding=my_embedding,query=This is some data)'][0]['score'],\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
